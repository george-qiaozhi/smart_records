# memo: Collect SMART data
This memo shows how to collect SMART data of disks on our server. The data collected will be correlated with workload information, I/O stat, and other environment attributes, for future analysis of our **disk failure prediction** project.
###### system configurations:
- Server s209: 
  - Seagate Barracuda 2TB HDD 3.5"FF x 4
  - Samsung 840 evo boot drive
  - SATA channel
- Server s211:
  - Intel SSD DC 240GB 2.5"FF x 4
  - HDD as boot drive
  - SATA channel


## prerequisites

##### smartctl 
- run as root

```
apt install smartmontools
smartctl -A /dev/sdb
```

##### cron background
- edit cron job list using preferred user account
  - for smartctl, root is a must have, so `su -` or just `su`
- `crontab -e` to edit the cron job list
```
SHELL=/bin/bash
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games

@hourly /home/zfs/SMART_cron/checkSMARThourly_v2.sh
```
- configure the PATH appropriately or use program's full path when invoke.
- available flags are @hourly @reboot @ monthly etc.
- OR, use `* * * * * [user] </script/path>` to specify cron job **every minute**

##### shell script
- currently in `/home/zfs/SMART_cron/check_smart_cron_per_minute.sh`
- using timestamp as file name: `date +%Y-%m-%d-%H-%M`
- Each disk have a dedicated directory for SMART data

## data collection
Currently we collect data for SSD stress test. The stress test use `dd if=xx of=yy oflag=dsync` to read input and write to output dir. ZFS is used to manage each SSD. SSD#0 is a single disk zpool that has input file `10G.dat`, which filled with random number generated by `openssl`. SSD#1 and SSD#2 is bundled by zfs via `zpool create -f outpool sdc sdd`, where data writes to, then removed. SSD#3 is another single disk pool, logs smart record every minutes. 

- From `crontab -e`, initiate cron job to record smart data every minute.
- once error detected, email notifications.

## results
Comming soon..
